{"cells":[{"cell_type":"markdown","metadata":{"id":"-9sHzIutjJxH"},"source":["#### Milestone project 1: Food Vision Big"]},{"cell_type":"markdown","metadata":{"id":"8MfsOTGwjdqW"},"source":["#### Check GPU\n","\n","Google colabs GPUs that are compatiable with `mixed_precision` training (7.0 or higher computing capabilities):\n","\n","* NVIDIA A100\n","* NVIDIA T4\n","* NVIDIA V100"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1653406896441,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"pquwLh2gjodd","outputId":"2ee7c393-e0f4-4812-901f-187f014b5773"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-16e6cf86-c649-c082-a44e-2bf4bebfb0d5)\n"]}],"source":["!nvidia-smi -L #nvidia t4 == tesla t4"]},{"cell_type":"markdown","metadata":{"id":"aCZwyjralO_p"},"source":["#### Import helper functions"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1653406897482,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"n2vT4U7fl8h1","outputId":"2d0ffbf8-193e-4396-be23-0243d2b3a16c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-24 15:41:36--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‘helper_functions.py’\n","\n","\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2022-05-24 15:41:36 (69.1 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6388,"status":"ok","timestamp":1653406903863,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"9YhVtjohmERE"},"outputs":[],"source":["import tensorflow as tf \n","import numpy as np \n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1653406903867,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"TM_bvg6JmPcA"},"outputs":[],"source":["from helper_functions import create_tensorboard_callback, unzip_data, plot_loss_curves, compare_historys"]},{"cell_type":"markdown","metadata":{"id":"CH_9bKRMmgw8"},"source":["#### Tensorflow datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1130,"status":"ok","timestamp":1653406904983,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"sKisXKz9WUBM"},"outputs":[],"source":["# import tensorflow datasets\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653406904985,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"aIwt_QWUXJQu","outputId":"3e155bc8-5c9d-4e46-c87b-2d2bd074b494"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["datasets_list = tfds.list_builders() # get all available datasets\n","print(\"food101\" in datasets_list) # the target datasets"]},{"cell_type":"markdown","metadata":{"id":"_jrY6xnxXZZ8"},"source":["#### Load in the data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["dbee3c9c2c2740b984caed5831fd0bef","91ca0c3df6d94627a73db48148ea6cce","fd5ec82fd5314f32b750f320aa60aa3a","ca0bad4c61b44944b428e0d2bc6664d4","3f5a2f519cf14f8e989b26468e4b583a","5052f997885545988764f068a1b24d8e","d0e17d2baa5747dd85c3ec27d6b73852","ef18cd822e4d4439a502f1d8ff0b786d","8f4e8eb232314701aba5d3bab593b861","a71da30fe59b408fbc50f3e51d664dab","e0f07d90c32a4eb88df055f6902f713f","80ceaf08861344e58043916807fc79e0","215d4d3c98ee457daa0b13b6caab2a4e","a964e85b42994d35bffc155d6f6a9632","44c6a36a88864eeba970cc78b0072e8f","191675820f204017938ac7c2b2f07a88","16f413f9ba2449eca9c12ea5f87eb21d","fea078c0d6744d779a3a05c1d5b28200","47a72460595941f4926eb83df80bba38","28dffb4ede574666b92d154b75ec1ae2","a295633cbb3d48eb8083e326abf1f6b8","41d564a1bcc74e539c0e53f9c24e8ecc","30c79eb65a744d4ab43c56b509625aa9","6e20975e875841a58e6ec7d03ba893e0","c8d7b83d4f0c4ec6a3382d42c1b8fd94","a4840fff03884f32a4dca42eaf730810","3722857f6f2b41d0b952306f4258249f","094354834b3440649543bd7edf719206","45b883b7cfe240999682079043387c15","cdd06adc7cb342f6a755fb431ad9c53d","d9f4df1566a54c0db543ad00dfb7bb21","021e38b270f645b5a4ec044d2f7d0380","d968ea785b5442f696f50c4b32d9a657","60c1e259b01d482ba3693c224c90d3b6","c495d4478ca2444f9b00820e3f230722","b8e10edc838e4359bfcc16a96f497bb3","6be3b59ab4084bdebfe656d2b2e7b23c","77a2b731f46841f193653e4ee6c7cd8d","c47d09a5b4de4341adc690e00eac621c","831d48881d2c4359a8c387f865b5b893","42c2f9a0af34478abd7fbee11862eb55","329cfc52d5f0461f8af6232624d33d03","4310cf75d1c747aabda94f02e732066b","4aa58501b7b34031ae6258b19d0d93be","8862927cf96a434cb6184718a993b316","9a7c94c240d54924aec38407079f31f2","ca1f1dc4b1cd43de93da1997895d724a","50bf719fd0fa4429b14cd2231794a0f6","fea6fa3c204945679d8a81c763578003","925d98e4f1d948088339e8e1954fd1de","164a3de027284998b2727eec09e0009e","42e2542aa1074961a696720f14bbf7a8","4cc5e0aafb254f1389bfe86155f57583","3278717c73064224949bc1369be6683d","0a226f059de84298a2d28798145091a9","098ef1df43b44307af191a8a210a5627","aa50bb2a928b4c83a5de7233ded02bcc","3e6687a9f6d848308dbc455fb61a7a5f","e4ac2b9b83fa47acbb8b3740a7e5c2d0","a176cec8ba6d4e0aa473b3a8ee585b05","340a27723b0f4d558abf54e6e5b5fb05","8700f9f4d1b8497a9a38b0b6506e2258","839b4c0f074946d39d682f21bcd0a775","7b6a53656752448fa8dd8d4c16d4c430","8a392973bc4b4773bc0889c927eff156","461a044d20f94bd7a0c72c776ebf092d","14819ecc578440b58f1f80f56a1d604c","037ab44cf1a74cce9136adcf5a9d9ad9","8116a671ec344fd2bd0fe7fe451827e2","7d602493c170495ca4b00adf8b01b100","3595fd090cac45f398934fd95654e815","f36104239d80477da4073fe4af49b437","af472e965b254d3392d3ac6a2dbacab3","d89fd785a83448b09810ecbd65ffb5b6","d49c634ddb4f4f32962ffff1e633ccbf","b3a68f09feb14e4d97b70e02b66edbd7","b8ac949b9d274744bc6a077f7e03a129"]},"executionInfo":{"elapsed":487860,"status":"ok","timestamp":1653407392837,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"z5oR0HIPXpI_","outputId":"e0b355c8-78c5-41e4-a22b-2f737d07c392"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mDownloading and preparing dataset food101/2.0.0 (download: 4.65 GiB, generated: Unknown size, total: 4.65 GiB) to /root/tensorflow_datasets/food101/2.0.0...\u001b[0m\n"]},{"output_type":"display_data","data":{"text/plain":["Dl Completed...: 0 url [00:00, ? url/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbee3c9c2c2740b984caed5831fd0bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dl Size...: 0 MiB [00:00, ? MiB/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ceaf08861344e58043916807fc79e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extraction completed...: 0 file [00:00, ? file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c79eb65a744d4ab43c56b509625aa9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60c1e259b01d482ba3693c224c90d3b6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/food101/2.0.0.incompleteTQ95FF/food101-train.tfrecord\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/75750 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8862927cf96a434cb6184718a993b316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098ef1df43b44307af191a8a210a5627"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/food101/2.0.0.incompleteTQ95FF/food101-validation.tfrecord\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/25250 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14819ecc578440b58f1f80f56a1d604c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1mDataset food101 downloaded and prepared to /root/tensorflow_datasets/food101/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"]}],"source":["(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n","                                             split=[\"train\", \"validation\"],\n","                                             shuffle_files=True,\n","                                             as_supervised=True, # data gets returned in tuple format\n","                                             with_info=True)"]},{"cell_type":"markdown","metadata":{"id":"LHuCW32-Yis3"},"source":["#### Features of the food101 from tfds"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1653407392837,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"trn4E6ZTam1-","outputId":"f76fe594-993e-4562-ad45-819ff31c03ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FeaturesDict({\n","    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n","    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),\n","})"]},"metadata":{},"execution_count":8}],"source":["ds_info.features"]},{"cell_type":"markdown","metadata":{"id":"nJCYxIECao0y"},"source":["#### Get the class names"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1653407392838,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"-FZZVptRaytJ","outputId":"0aaf3d8c-db1b-4466-857f-aaccb4daeb03"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['apple_pie',\n"," 'baby_back_ribs',\n"," 'baklava',\n"," 'beef_carpaccio',\n"," 'beef_tartare',\n"," 'beet_salad',\n"," 'beignets',\n"," 'bibimbap',\n"," 'bread_pudding',\n"," 'breakfast_burrito']"]},"metadata":{},"execution_count":9}],"source":["class_names = ds_info.features[\"label\"].names\n","class_names[:10]"]},{"cell_type":"markdown","metadata":{"id":"wTqynydra7kA"},"source":["#### Explore the food101 dataset\n","\n","* Class names\n","* The shape of the input image\n","* The datatype of the input data\n","* Labels format (one-hot encoded or label-encoded)\n","* Labels == class names?"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1653407393333,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"ypGWrFkibESu","outputId":"9c6021fd-0921-4a5e-a3fc-fb05aabd2bd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":10}],"source":["train_data_sample = train_data.take(1) # samples are in the format of image_tensor and label\n","train_data_sample # view 1 sample of the training data"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1641,"status":"ok","timestamp":1653407394968,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"avEsl6t4br9p","outputId":"ee3b3814-dbf4-465f-d9f3-f3762ba319ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Image shape: (512, 512, 3)\n","  Image datatype: <dtype: 'uint8'>\n","  Target class from Food101 (tensor form): 41\n","  Class name (str form): french_onion_soup\n","  \n"]}],"source":["for image, label in train_data_sample: # output info \n","  print(f\"\"\"\n","  Image shape: {image.shape}\n","  Image datatype: {image.dtype}\n","  Target class from Food101 (tensor form): {label}\n","  Class name (str form): {class_names[label.numpy()]}\n","  \"\"\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1653407394969,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"I-Zjya1HclqH","outputId":"928a661c-9378-4769-8aa1-7727981ebb84"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(512, 512, 3), dtype=uint8, numpy=\n","array([[[168, 148, 123],\n","        [192, 172, 147],\n","        [200, 180, 155],\n","        ...,\n","        [179, 165, 139],\n","        [188, 172, 147],\n","        [154, 138, 113]],\n","\n","       [[184, 164, 139],\n","        [209, 189, 164],\n","        [212, 192, 167],\n","        ...,\n","        [207, 193, 167],\n","        [218, 202, 177],\n","        [184, 168, 143]],\n","\n","       [[186, 166, 139],\n","        [214, 194, 167],\n","        [211, 194, 168],\n","        ...,\n","        [207, 193, 167],\n","        [217, 203, 177],\n","        [180, 166, 140]],\n","\n","       ...,\n","\n","       [[206, 198, 179],\n","        [236, 228, 209],\n","        [230, 221, 204],\n","        ...,\n","        [226, 214, 200],\n","        [239, 227, 211],\n","        [203, 191, 175]],\n","\n","       [[216, 208, 187],\n","        [239, 231, 210],\n","        [233, 225, 206],\n","        ...,\n","        [227, 215, 201],\n","        [237, 225, 209],\n","        [205, 193, 177]],\n","\n","       [[173, 165, 144],\n","        [198, 190, 169],\n","        [204, 196, 177],\n","        ...,\n","        [197, 185, 171],\n","        [204, 192, 176],\n","        [172, 160, 144]]], dtype=uint8)>"]},"metadata":{},"execution_count":12}],"source":["image"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1653407394969,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"kn_IzFsjcshu","outputId":"d494ecbe-8146-42ef-a596-8c4df12ef500"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(), dtype=uint8, numpy=0>,\n"," <tf.Tensor: shape=(), dtype=uint8, numpy=255>)"]},"metadata":{},"execution_count":13}],"source":["tf.reduce_min(image), tf.reduce_max(image) # min and max values of the image tensor"]},{"cell_type":"markdown","metadata":{"id":"cKovD15Oc5wF"},"source":["#### Plot an image from the tensorflow datasets"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":866,"status":"ok","timestamp":1653407395829,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"xU9oeyHqdHP4","outputId":"47c2ca03-2d6d-416c-d3ea-867c708b63a1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt \n","plt.imshow(image)\n","plt.title(class_names[label.numpy()]) # add title to verify the image with the right classification\n","plt.axis=False"]},{"cell_type":"markdown","metadata":{"id":"E4hnGvqAdhPt"},"source":["#### Create preprocessing functions for the data\n","\n","- Neural networks perform best when data is in a certain format (e.g. batched, normalized, etc)\n","\n","Our food101 data from tfds is in:\n","\n","* In `uint8` datatype\n","* Different sized tensors \n","* Not scaled\n","\n","The target image format:\n","* Data type of `float32` or `mixed_precision` `float16` \n","* Batch size to be the same with same image sizes\n","* Scaled values (0-1)\n","\n","Our function needs to:\n","1. Reshape the images to all the same size\n","2. Convert the dtype of the image tensors from `uint8` to `float32`"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1653407395830,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"kKGbutijeRJv"},"outputs":[],"source":["def preprocess_img(image, label, img_shape=224):\n","  \"\"\"\n","  Converts image datatype from 'uint8' => 'float32' and reshapes\n","  image tp [img_shape, image_shape, color_channels]\n","  \"\"\"\n","\n","  image = tf.image.resize(image, [img_shape, img_shape]) # reshape target image\n","  # image = image/255. # scale image if transfer learning model is not EfficientNetB0\n","  return tf.cast(image, tf.float32), label # return tuple of image in float32 and label"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1653407395831,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"pD_C9Qq4hHQf","outputId":"e598d954-1a09-4e1a-cc0c-8e8bd251486e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Image before preprocessing:\n"," [[[168 148 123]\n","  [192 172 147]\n","  [200 180 155]\n","  ...\n","  [179 165 139]\n","  [188 172 147]\n","  [154 138 113]]\n","\n"," [[184 164 139]\n","  [209 189 164]\n","  [212 192 167]\n","  ...\n","  [207 193 167]\n","  [218 202 177]\n","  [184 168 143]]]..., \n","Shape: (512, 512, 3), \n","Datatype: <dtype: 'uint8'>\n","\n","Image after preprocessing:\n"," [[[194.12755 174.12755 149.12755]\n","  [204.66325 184.66325 159.66325]\n","  [198.20918 180.42348 158.85204]\n","  ...\n","  [200.12253 186.55106 160.97958]\n","  [204.22949 190.22949 164.22949]\n","  [195.14168 179.14168 154.14168]]\n","\n"," [[197.10204 177.10204 150.10204]\n","  [202.5102  185.5102  159.5102 ]\n","  [209.96428 193.83673 169.47958]\n","  ...\n","  [201.301   187.72952 162.15805]\n","  [207.8622  193.8622  167.8622 ]\n","  [197.218   183.218   157.218  ]]]..., \n","Shape: (224, 224, 3), \n","Datatype: <dtype: 'float32'>\n","\n"]}],"source":["preprocessed_img = preprocess_img(image, label)[0]\n","print(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\\n\")\n","print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}..., \\nShape: {preprocessed_img.shape}, \\nDatatype: {preprocessed_img.dtype}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"ljjR1sG_h32n"},"source":["#### Batch and prepare datasets"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653407395832,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"3TeilFGaivHJ"},"outputs":[],"source":["# map preprocessing function to training data\n","train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n","train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE) # buffer_size == the number of elements to shuffle at the same time\n","\n","# map preprocessing function to test data\n","test_data = test_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653407395833,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"Zs1J3sU4jOqv","outputId":"0a7d3f17-5c7d-43c3-c4d8-eabff9e795b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n"," <PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"]},"metadata":{},"execution_count":18}],"source":["train_data, test_data"]},{"cell_type":"markdown","metadata":{"id":"w8iBwZWQlnNV"},"source":["#### Create modelling callbacks\n","\n","* Tensorboard callback - log training results\n","* ModelCheckpoint callback - to save the model's progress after feature extraction"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1653407395834,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"j5hpvS8vh-4m"},"outputs":[],"source":["from helper_functions import create_tensorboard_callback # import function\n","\n","checkpoint_path = \"model_checkpoints/cp.ckpt\"\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                                      monitor=\"val_accuracy\",\n","                                                      save_best_only=True,\n","                                                      save_weights_only=True,\n","                                                      verbose=0) # verbose = 0 means no printed output"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":78726,"status":"ok","timestamp":1653407474546,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"oQ7N4v5mkTP1","outputId":"04b336d5-ee63-42ad-aa98-36e9f33756b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.4.1\n","  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n","\u001b[K     |████████████████████████████████| 394.3 MB 12 kB/s \n","\u001b[?25hCollecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting grpcio~=1.32.0\n","  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n","Collecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting h5py~=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 51.3 MB/s \n","\u001b[?25hCollecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0\n","  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 67.5 MB/s \n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68722 sha256=16c423264ca03abacd9176b8b36e4e3ceaca389d58da54d52feffe7e59be17c6\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built wrapt\n","Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.46.1\n","    Uninstalling grpcio-1.46.1:\n","      Successfully uninstalled grpcio-1.46.1\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.0.0\n","    Uninstalling absl-py-1.0.0:\n","      Successfully uninstalled absl-py-1.0.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n","    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n","      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["absl","flatbuffers","gast","h5py","numpy","tensorflow","typing_extensions","wrapt"]}}},"metadata":{}}],"source":["!pip install tensorflow==2.4.1"]},{"cell_type":"markdown","metadata":{"id":"bDNRWdomko6V"},"source":["#### Set up mixed precision training\n","\n","- Mixed precision uses a combination `float16` and `float32` to speed up the model's performance"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1653407474547,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"V96daK9MlMgI","outputId":"a8614172-4245-48f0-a468-cfe68707ddc8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1653407474549,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"pB_lCpNNlRpI","outputId":"38a0cb2c-be5a-43f7-be99-9ca9afd3b941"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n"]}],"source":["from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy(\"mixed_float16\") # set global policy to mixed precision"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676,"status":"ok","timestamp":1653407475200,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"W864CizRmtql","outputId":"d5e5d177-d2fe-4569-88ae-ff74771b5ce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-16e6cf86-c649-c082-a44e-2bf4bebfb0d5)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1653407475201,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"r3KkbtJ_mwSy","outputId":"35243174-a998-45af-ba07-9d25ccfc40bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue May 24 15:51:14 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    28W /  70W |    266MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1653407475202,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"8WjgmKdnmzAl","outputId":"148f2a59-50f4-4f88-d12e-52a021a7ae09"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Policy \"mixed_float16\">"]},"metadata":{},"execution_count":25}],"source":["mixed_precision.global_policy()"]},{"cell_type":"markdown","metadata":{"id":"RF0p9ccNm_v6"},"source":["#### Build a feature extraction model"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653407475202,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"e9SoCBrWp1RE","outputId":"3dc53c1b-abbd-4db2-ff79-7ee519db5503"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["101"]},"metadata":{},"execution_count":26}],"source":["len(class_names)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1653407475203,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"mds6bzRQp6NO","outputId":"a8f532de-6672-48f3-f575-66152b953acd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=int64, numpy=41>"]},"metadata":{},"execution_count":27}],"source":["label"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3970,"status":"ok","timestamp":1653407479165,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"RUolPeBKogH7","outputId":"5687060e-d632-471c-8acc-ea4e93043d08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","16711680/16705208 [==============================] - 0s 0us/step\n","16719872/16705208 [==============================] - 0s 0us/step\n"]}],"source":["from tensorflow.keras import layers \n","from tensorflow.keras.layers.experimental import preprocessing \n","\n","# 1. create base model\n","input_shape = (224, 224, 3)\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False) \n","base_model.trainable = False \n","\n","# 2. create functional model\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\") \n","x = base_model(inputs, training=False) # make sure layers is in inference\n","x =  layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(len(class_names))(x) \n","outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"output_layer\")(x) \n","model = tf.keras.Model(inputs, outputs) \n","\n","# compile the model \n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(), \n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1653407479166,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"-cxA7ymAqITC","outputId":"aa91e58f-a078-41ec-99da-4ddeb1b57176"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n","                                                                 \n"," efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n","                                                                 \n"," global_average_pooling2d (G  (None, 1280)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 101)               129381    \n","                                                                 \n"," output_layer (Activation)   (None, 101)               0         \n","                                                                 \n","=================================================================\n","Total params: 4,178,952\n","Trainable params: 129,381\n","Non-trainable params: 4,049,571\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"sflIxC2oqhsu"},"source":["Check layer dtype policies (mixed_precision)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653407479166,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"7TytCt9JqMCd","outputId":"e6815381-c120-47c6-906d-a4ee6520b296"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_layer True float32 <Policy \"float32\">\n","efficientnetb0 False float32 <Policy \"mixed_float16\">\n","global_average_pooling2d True float32 <Policy \"mixed_float16\">\n","dense True float32 <Policy \"mixed_float16\">\n","output_layer True float32 <Policy \"float32\">\n"]}],"source":["for layer in model.layers:\n","  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"]},{"cell_type":"markdown","metadata":{"id":"2iWu5WT8q88G"},"source":["* `layer.name`: name of the layer\n","* `layer.trainable`: is the layer trainable\n","* `layer.dtype`: the data type the layer stores its variables\n","* `layer.dtype_policy`: the data type policy a layer computes on its variables"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653407479167,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"JD2ADKEvqdNH","outputId":"c8477f80-9d4c-4f8f-f3af-698671a55d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_1 False float32 <Policy \"float32\">\n","rescaling False float32 <Policy \"mixed_float16\">\n","normalization False float32 <Policy \"mixed_float16\">\n","stem_conv_pad False float32 <Policy \"mixed_float16\">\n","stem_conv False float32 <Policy \"mixed_float16\">\n","stem_bn False float32 <Policy \"mixed_float16\">\n","stem_activation False float32 <Policy \"mixed_float16\">\n","block1a_dwconv False float32 <Policy \"mixed_float16\">\n","block1a_bn False float32 <Policy \"mixed_float16\">\n","block1a_activation False float32 <Policy \"mixed_float16\">\n","block1a_se_squeeze False float32 <Policy \"mixed_float16\">\n","block1a_se_reshape False float32 <Policy \"mixed_float16\">\n","block1a_se_reduce False float32 <Policy \"mixed_float16\">\n","block1a_se_expand False float32 <Policy \"mixed_float16\">\n","block1a_se_excite False float32 <Policy \"mixed_float16\">\n","block1a_project_conv False float32 <Policy \"mixed_float16\">\n","block1a_project_bn False float32 <Policy \"mixed_float16\">\n","block2a_expand_conv False float32 <Policy \"mixed_float16\">\n","block2a_expand_bn False float32 <Policy \"mixed_float16\">\n","block2a_expand_activation False float32 <Policy \"mixed_float16\">\n"]}],"source":["for layer in model.layers[1].layers[:20]: # layers in EfficientNetB0\n","  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1653407479167,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"mFMxyyicrwlx","outputId":"1bfe6606-ff87-436f-8f1d-ad3a3e8771af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Policy \"mixed_float16\">"]},"metadata":{},"execution_count":32}],"source":["mixed_precision.global_policy()"]},{"cell_type":"markdown","metadata":{"id":"XNyxuxnzsLdy"},"source":["#### Fit the feature extraction model\n","\n","1. Build a feature extraction model\n","2. Fine-tune some of the frozen layers"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587268,"status":"ok","timestamp":1653408066424,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"fNlzHOZwsZ1U","outputId":"324df620-bae9-4c3f-e78d-9b969c551aa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: training_logs/efficientnetb0_101_classes_all_data_feature_extraction/20220524-155118\n","Epoch 1/3\n","2368/2368 [==============================] - 239s 89ms/step - loss: 1.8221 - accuracy: 0.5557 - val_loss: 1.2256 - val_accuracy: 0.6809\n","Epoch 2/3\n","2368/2368 [==============================] - 177s 74ms/step - loss: 1.2939 - accuracy: 0.6664 - val_loss: 1.1217 - val_accuracy: 0.7005\n","Epoch 3/3\n","2368/2368 [==============================] - 170s 71ms/step - loss: 1.1419 - accuracy: 0.7022 - val_loss: 1.0821 - val_accuracy: 0.7087\n"]}],"source":["history_101_food_classes_feature_extraction = model.fit(train_data,\n","                                                        epochs=3,\n","                                                        steps_per_epoch=len(train_data),\n","                                                        validation_data=test_data, \n","                                                        validation_steps=int(0.15 * len(test_data)),\n","                                                        callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n","                                                                                               experiment_name=\"efficientnetb0_101_classes_all_data_feature_extraction\"),\n","                                                                   model_checkpoint])"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82028,"status":"ok","timestamp":1653408148436,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"18MAhNPlttH_","outputId":"c6edfab1-d796-4cf6-a87c-2a291663990f"},"outputs":[{"output_type":"stream","name":"stdout","text":["790/790 [==============================] - 49s 62ms/step - loss: 1.0863 - accuracy: 0.7074\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.0863054990768433, 0.7073663473129272]"]},"metadata":{},"execution_count":34}],"source":["# evaluate the model\n","results_feature_extract_model = model.evaluate(test_data)\n","results_feature_extract_model"]},{"cell_type":"markdown","metadata":{"id":"VZJaqXJ8upQk"},"source":["#### Fine-tune the model to beat 77.4% `val_accuracy`"]},{"cell_type":"markdown","metadata":{"id":"eU4Mea88vGAD"},"source":["#### Save  and load model"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41886,"status":"ok","timestamp":1653408190317,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"rzsC7z_IiPeX","outputId":"523fdc79-c806-4359-fd08-e56fdd851493"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe07cb7fe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unknown node type <gast.gast.Expr object at 0x7fe070238690>\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe07cb7fe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unknown node type <gast.gast.Expr object at 0x7fe070238690>\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe07cb7fe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: Unknown node type <gast.gast.Expr object at 0x7fe070238690>\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cc3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cca70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cca70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811cca70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811ccb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811ccb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811ccb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113cb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113cb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113cb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe08113c950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811603b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811603b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0811603b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe081160d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1073824d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1073824d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1073824d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe107382e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072db710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b64d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b64d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b64d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b65f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b65f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b65f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1072b6ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10727de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071da7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071daf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071daf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071daf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe1071bc8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe10711e8c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f804170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f804170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f804170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f81ab00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f81ab00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f81ab00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f7c3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f7c3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f7c3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ea290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ea290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ea290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ffcb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ffcb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6ffcb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6a74d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6a74d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f6a74d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f686440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f686440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f686440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f69be60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f69be60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f69be60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f608680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f608680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f608680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f575dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f575dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f575dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f525830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f525830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f525830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f550050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f550050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f550050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f515f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f515f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f515f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f4869e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f4869e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f4869e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f42e200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f42e200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f42e200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f421950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f421950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f421950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f39f3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f39f3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f39f3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f33db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f33db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f33db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f313b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f313b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f313b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f280560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f280560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f280560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f294d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f294d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f294d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f2194d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f2194d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f2194d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1aeef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1aeef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1aeef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1d0710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1d0710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f1d0710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0fee60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0fee60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0fee60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0288c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0288c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0288c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07f0520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efb2050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efb2050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efb2050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efc5a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efc5a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07efc5a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef31290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef31290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef31290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef239e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef239e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ef239e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eecc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eecc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eecc440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ee2bc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ee2bc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ee2bc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eda73b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eda73b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eda73b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07edc9f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07edc9f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07edc9f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed7d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed7d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed7d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed54560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed54560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ed54560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecadf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecadf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecadf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecde7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecde7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ecde7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ec07ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ec07ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ec07ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebb5950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebb5950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebb5950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebe3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebe3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ebe3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eb138c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eb138c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eb138c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eabd320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eabd320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07eabd320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ead9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ead9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ead9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ea5b290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ea5b290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07ea5b290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9b0c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9b0c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9b0c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9cf4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9cf4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e9cf4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e928440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e928440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07e928440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7f440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07cb7fb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9175f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9175f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9175f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c917830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9714d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9714d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9714d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9715f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9715f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9715f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9719e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9719e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c9719e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c971ef0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8950e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8950e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8950e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c8959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c895e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7953b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7953b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7953b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7954d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7958c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7958c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7958c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c7959e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c795f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c6733b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c6733b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c6733b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c673b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a93b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a93b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a93b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a97a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a97a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a97a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a98c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a98c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a98c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5a9a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5303b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5303b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5303b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c530d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5309e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5309e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c5309e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c4737a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c4737a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c4737a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c473c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3dd680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c3ddb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c2345f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c2345f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c2345f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe07c234f80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700923b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700923b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700923b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700927a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700927a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700927a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe070092d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700929e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700929e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fe0700929e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe3387a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe3387a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe3387a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe338c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28d680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28dc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28dc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28dc20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe28db90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbb90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1db200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1dbf80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1833b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1833b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1833b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1834d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1834d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1834d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1835f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1835f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1835f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1839e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1839e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe1839e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe183e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb950> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbd40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbd40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbd40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fbe60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0fb5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0173b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0173b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0173b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0178c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0178c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe0178c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017dd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdffe017a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a33b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a33b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a33b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3830> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a37a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a37a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a37a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a3d40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a39e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a39e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea3a39e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c60e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c60e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c60e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c67a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c67a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c67a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6cb0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2c6c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2524d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2524d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2524d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea2520e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea252b90> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189170> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1894d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1894d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1894d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1895f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1895f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea1895f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea189a70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea09a3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea09a3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea09a3b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea0557a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea0557a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfea0557a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7fe1560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7fe1560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7fe1560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7f14290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7f14290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7f14290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ec9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ec9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ec9b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e838c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e838c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e838c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e35560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e35560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7e35560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7df99e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7df99e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7df99e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7db17a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7db17a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7db17a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ca2290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ca2290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7ca2290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c58b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c58b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c58b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c108c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c108c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7c108c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7bbf5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7bbf5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7bbf5f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b739e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b739e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b739e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b2d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b2d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7b2d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7a1d290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7a1d290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7a1d290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79d3b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79d3b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79d3b00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79898c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79898c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe79898c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78c35f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78c35f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78c35f0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78f59e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78f59e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78f59e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78be7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78be7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe78be7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe77aa290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe77aa290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe77aa290> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7765680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7765680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7765680> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe771d440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe771d440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe771d440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe764def0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe764def0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe764def0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe763b320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe763b320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe763b320> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe75ee0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe75ee0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe75ee0e0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe756cdd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe756cdd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe756cdd0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe74e2200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe74e2200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe74e2200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7494200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7494200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7494200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe73cba70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe73cba70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe73cba70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7383e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7383e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7383e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7341c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7341c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7341c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe72bf710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe72bf710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe72bf710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe726ef80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe726ef80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe726ef80> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe722ad40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe722ad40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe722ad40> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe715aa70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe715aa70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe715aa70> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7112e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7112e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe7112e60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe70d2c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe70d2c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe70d2c20> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe703a710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe703a710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe703a710> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fedb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fedb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fedb00> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fa38c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fa38c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6fa38c0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e943b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e943b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e943b0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e4d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e4d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e4d7a0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e08560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e08560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6e08560> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d6d050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d6d050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d6d050> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d30440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d30440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6d30440> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6ce4200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6ce4200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6ce4200> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6c5de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6c5de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function _graph_mode_decorator.<locals>.internal_grad_fn at 0x7fdfe6c5de60> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('tape_grad_fn',), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","INFO:tensorflow:Assets written to: 07_efficientnetb0_feature_extraction_model_mixed_precision/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: 07_efficientnetb0_feature_extraction_model_mixed_precision/assets\n"]}],"source":["save_dir = \"07_efficientnetb0_feature_extraction_model_mixed_precision\" # save model locally\n","model.save(save_dir)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":13747,"status":"ok","timestamp":1653408204058,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"gSrhYmOyirzo"},"outputs":[],"source":["loaded_saved_model = tf.keras.models.load_model(save_dir)"]},{"cell_type":"markdown","metadata":{"id":"SDFLjQRejBfd"},"source":["Check layers in `base_model`"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1653408204059,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"Ry-UDWWxi6VJ","outputId":"b0e85da1-5bfc-4b92-e758-4cb3c6b2b532"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_1 True float32 <Policy \"float32\">\n","rescaling False float32 <Policy \"mixed_float16\">\n","normalization False float32 <Policy \"mixed_float16\">\n","stem_conv_pad False float32 <Policy \"mixed_float16\">\n","stem_conv False float32 <Policy \"mixed_float16\">\n","stem_bn False float32 <Policy \"mixed_float16\">\n","stem_activation False float32 <Policy \"mixed_float16\">\n","block1a_dwconv False float32 <Policy \"mixed_float16\">\n","block1a_bn False float32 <Policy \"mixed_float16\">\n","block1a_activation False float32 <Policy \"mixed_float16\">\n","block1a_se_squeeze False float32 <Policy \"mixed_float16\">\n","block1a_se_reshape False float32 <Policy \"mixed_float16\">\n","block1a_se_reduce False float32 <Policy \"mixed_float16\">\n","block1a_se_expand False float32 <Policy \"mixed_float16\">\n","block1a_se_excite False float32 <Policy \"mixed_float16\">\n","block1a_project_conv False float32 <Policy \"mixed_float16\">\n","block1a_project_bn False float32 <Policy \"mixed_float16\">\n","block2a_expand_conv False float32 <Policy \"mixed_float16\">\n","block2a_expand_bn False float32 <Policy \"mixed_float16\">\n","block2a_expand_activation False float32 <Policy \"mixed_float16\">\n"]}],"source":["for layer in loaded_saved_model.layers[1].layers[:20]:\n","  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"]},{"cell_type":"markdown","metadata":{"id":"axc_0r5qjTl9"},"source":["#### Evaluate `loaded_saved_model`"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84481,"status":"ok","timestamp":1653408288523,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"jI5C2m5fjiDP","outputId":"d42cec9a-671d-4547-d7e3-51017a357728"},"outputs":[{"output_type":"stream","name":"stdout","text":["790/790 [==============================] - 50s 61ms/step - loss: 1.0863 - accuracy: 0.7074\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.0863059759140015, 0.7073663473129272]"]},"metadata":{},"execution_count":38}],"source":["results_loaded_model = loaded_saved_model.evaluate(test_data)\n","results_loaded_model"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1653408288524,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"IP-28tgGl8Wt"},"outputs":[],"source":["import numpy as np \n","assert np.isclose(results_feature_extract_model, results_loaded_model).all()"]},{"cell_type":"markdown","metadata":{"id":"Rf9XVtMqjq-m"},"source":["#### Download saved model from Google storage"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1653408289047,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"zrh5sKYnkLXb","outputId":"de641ddb-1319-4711-87ff-2dfa4b8bab65"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-24 16:04:48--  https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 108.177.121.128, 142.250.103.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16976857 (16M) [application/zip]\n","Saving to: ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’\n","\n","07_efficientnetb0_f 100%[===================>]  16.19M  --.-KB/s    in 0.1s    \n","\n","2022-05-24 16:04:48 (119 MB/s) - ‘07_efficientnetb0_feature_extract_model_mixed_precision.zip’ saved [16976857/16976857]\n","\n"]}],"source":["!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip "]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1653408289692,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"hCh16PTgkMc8","outputId":"d4b39221-43ef-42dd-cb8a-99ee20d6c4fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  07_efficientnetb0_feature_extract_model_mixed_precision.zip\n","   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/\n","   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/\n","  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.data-00000-of-00001  \n","  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/variables/variables.index  \n","  inflating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/saved_model.pb  \n","   creating: downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision/assets/\n"]}],"source":["!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n","!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"]},{"cell_type":"markdown","metadata":{"id":"5JG63hzSlIaS"},"source":["Load and evaluate downloaded model"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13808,"status":"ok","timestamp":1653408303492,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"t2i4aZcgkt5b","outputId":"e0a1d464-50ea-454e-aec8-2b0afb876ffb"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n","WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_158253) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_191539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_196076) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_195780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_196153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_180010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_191136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_160354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_195703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_159392) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_191213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_193678) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_194051) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_158768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_191907) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_162720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_194708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_196195) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_194258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_188022) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_161995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_183149) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_158824) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_159787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_158482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_158588) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_195449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_194377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_162615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_192238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_160121) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_192860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_191865) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_160016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_194750) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_169029) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_170771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_159448) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_194631) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_192979) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_193263) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_160977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_162953) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_159836) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_191581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_158539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_162382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_196449) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_163238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_162277) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_192487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_191255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_163009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_194335) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_193559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_159730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_161759) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_192161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_193305) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_160748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_161371) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_192937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_196568) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_191788) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_159106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_159497) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_161315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_184891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_model_layer_call_and_return_conditional_losses_178256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_161710) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_161653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_159212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_158197) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_efficientnetb0_layer_call_and_return_conditional_losses_189764) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_192606) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_195081) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_162333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_160797) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_194009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_195822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_161033) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_195330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_159163) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_160459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_195407) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_163058) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_192280) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_162671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference__wrapped_model_152628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_162044) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_158873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_160410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_195004) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_192564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_161082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_161420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_193636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_196775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_160072) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_161939) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_193932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_193186) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_158302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_195123) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_191462) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_196526) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_160692) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"]}],"source":["tf.get_logger().setLevel(\"INFO\") # hide warning logs\n","loaded_gs_model = tf.keras.models.load_model(\"downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"]},{"cell_type":"markdown","metadata":{"id":"a2TBgkg8lgP1"},"source":["Summary of downloaded model"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1653408303493,"user":{"displayName":"Chittebabu Masilamony","userId":"00540476393573736761"},"user_tz":-480},"id":"u6QyB9DSlaRY","outputId":"01d05f94-adb4-4e2d-f0df-36863f1fed9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n","                                                                 \n"," efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n","                                                                 \n"," pooling_layer (GlobalAverag  (None, 1280)             0         \n"," ePooling2D)                                                     \n","                                                                 \n"," dense (Dense)               (None, 101)               129381    \n","                                                                 \n"," softmax_float32 (Activation  (None, 101)              0         \n"," )                                                               \n","                                                                 \n","=================================================================\n","Total params: 4,178,952\n","Trainable params: 129,381\n","Non-trainable params: 4,049,571\n","_________________________________________________________________\n"]}],"source":["loaded_gs_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"1DVTqWGellYY"},"source":["#### Evaluate the `loaded_gs_model`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0SrBuqvm3XQ","outputId":"b3771ee4-188c-4624-80a9-142bd2914f01"},"outputs":[{"output_type":"stream","name":"stdout","text":["790/790 [==============================] - 51s 61ms/step - loss: 1.0881 - accuracy: 0.7065\n"]}],"source":["results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n","results_loaded_gs_model"]},{"cell_type":"markdown","metadata":{"id":"ofOTt9Yvm9r1"},"source":["#### Set all layers.trainable to be True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yRt2CeLnRqV"},"outputs":[],"source":["for layer in loaded_gs_model.layers[1].layers:\n","  layer.trainable = True\n","  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"]},{"cell_type":"markdown","metadata":{"id":"wNoxkBQFonZo"},"source":["#### Set up callback functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bD3NlDbo4yt"},"outputs":[],"source":["early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # early stopping callback to stop running when there is no improvement in val_loss\n","                                                  patience=3)\n","\n","checkpoint_path = \"fine_tune_checkpoints/cp.ckpt\" # model checkpoint callback\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n","                                                      save_best_only=True, \n","                                                      # save_weights_only=True, \n","                                                      # save_freq=True, \n","                                                      monitor=\"val_loss\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjnBLUN7pzy1"},"outputs":[],"source":["reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", # reduce learning rate callback\n","                                                 factor=0.2, \n","                                                 patience=2,\n","                                                 verbose=1, # print out when learning rate goes down\n","                                                 min_lr=1e-7)"]},{"cell_type":"markdown","metadata":{"id":"Hl9hYbKNqWRA"},"source":["#### Compile the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWlQMSFPqdcM"},"outputs":[],"source":["loaded_gs_model.compile(loss=\"sparse_categorical_crossentropy\", \n","                        optimizer=tf.keras.optimizers.Adam(0.0001),\n","                        metrics=[\"accuracy\"])"]},{"cell_type":"markdown","metadata":{"id":"B3F9ZXSPqrnx"},"source":["#### Fit the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hxGgxLpTqt4A"},"outputs":[],"source":["history_101_food_classes_fine_tune = loaded_gs_model.fit(train_data, \n","                                                         epochs=100,\n","                                                         steps_per_epoch=len(train_data), \n","                                                         validation_data=test_data, \n","                                                         validation_steps=int(0.15 * len(test_data)), \n","                                                         callbacks=[create_tensorboard_callback(dir_name=\"training_logs\",\n","                                                                                                experiment_name=\"efficientnetb0_101_classes_fine_tune\"),\n","                                                                    model_checkpoint, # save only the best model\n","                                                                    early_stopping, # stop model after x epochs of no improvements\n","                                                                    reduce_lr]) # reduce learning rate after x epochs of no improvements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmnvaXUzrn7q"},"outputs":[],"source":["loaded_gs_model.save(\"07_efficientnetb0_fine_tune_101_food_classes_mixed_precision\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xR2Glg0nsAfe"},"outputs":[],"source":["results_loaded_gs_model_fine_tune = loaded_gs_model.evaluate(test_data)\n","results_loaded_gs_model_fine_tune"]},{"cell_type":"markdown","metadata":{"id":"vBerkHlKsMjA"},"source":["#### Export to TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GjQTaJ8smVo"},"outputs":[],"source":["!tensorboard dev upload --logdir ./training_logs \\\n","  --name \"Fine-tuning EfficientNetB0 on all Food101 data\" \\\n","  --description \"Training results for fine-tuning EfficientNetB0 on Food101 data with learning rate 0.0001\" \\"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVoO4WQ_tEf1"},"outputs":[],"source":["!tensorboard dev list"]},{"cell_type":"markdown","metadata":{"id":"2V5vLgz5t-VL"},"source":["#### Create confusion matrix and classification report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4D2S2lFstKtw"},"outputs":[],"source":["from helper_functions import make_confusion_matrix\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SKl9LswkuDT3"},"outputs":[],"source":["pred_probs = loaded_gs_model.predict(test_data)\n","len(pred_probs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EACXFTquPlS"},"outputs":[],"source":["pred_classes = pred_probs.argmax(axis=1)\n","pred_classes[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9s9pp84ueGK"},"outputs":[],"source":["y_labels = []\n","for images, labels in test_data.unbatch(): \n","  y_labels.append(labels.numpy().argmax())\n","y_labels[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezJCiRXdu3uZ"},"outputs":[],"source":["class_names = test_data.class_names\n","class_names[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMo5615ZvHMc"},"outputs":[],"source":["make_confusion_matrix(y_true=y_labels, \n","                      y_pred=pred_classes, \n","                      class_names=class_names, \n","                      figsize=(100, 100), \n","                      text_size=20, \n","                      savefig=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQq5jSUcvo7w"},"outputs":[],"source":["print(classification_report(y_true=y_labels, \n","                            y_pred=pred_classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CtdazenvyB4"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"07_milestone_project_1_food_vision.ipynb","provenance":[],"collapsed_sections":["wTqynydra7kA","cKovD15Oc5wF","E4hnGvqAdhPt","ljjR1sG_h32n","w8iBwZWQlnNV","bDNRWdomko6V","RF0p9ccNm_v6","VZJaqXJ8upQk"],"authorship_tag":"ABX9TyNYrz44oEZE13xpM6MJCikh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dbee3c9c2c2740b984caed5831fd0bef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91ca0c3df6d94627a73db48148ea6cce","IPY_MODEL_fd5ec82fd5314f32b750f320aa60aa3a","IPY_MODEL_ca0bad4c61b44944b428e0d2bc6664d4"],"layout":"IPY_MODEL_3f5a2f519cf14f8e989b26468e4b583a"}},"91ca0c3df6d94627a73db48148ea6cce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5052f997885545988764f068a1b24d8e","placeholder":"​","style":"IPY_MODEL_d0e17d2baa5747dd85c3ec27d6b73852","value":"Dl Completed...: 100%"}},"fd5ec82fd5314f32b750f320aa60aa3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef18cd822e4d4439a502f1d8ff0b786d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f4e8eb232314701aba5d3bab593b861","value":1}},"ca0bad4c61b44944b428e0d2bc6664d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a71da30fe59b408fbc50f3e51d664dab","placeholder":"​","style":"IPY_MODEL_e0f07d90c32a4eb88df055f6902f713f","value":" 1/1 [04:33&lt;00:00, 190.89s/ url]"}},"3f5a2f519cf14f8e989b26468e4b583a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5052f997885545988764f068a1b24d8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e17d2baa5747dd85c3ec27d6b73852":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef18cd822e4d4439a502f1d8ff0b786d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8f4e8eb232314701aba5d3bab593b861":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a71da30fe59b408fbc50f3e51d664dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f07d90c32a4eb88df055f6902f713f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80ceaf08861344e58043916807fc79e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_215d4d3c98ee457daa0b13b6caab2a4e","IPY_MODEL_a964e85b42994d35bffc155d6f6a9632","IPY_MODEL_44c6a36a88864eeba970cc78b0072e8f"],"layout":"IPY_MODEL_191675820f204017938ac7c2b2f07a88"}},"215d4d3c98ee457daa0b13b6caab2a4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16f413f9ba2449eca9c12ea5f87eb21d","placeholder":"​","style":"IPY_MODEL_fea078c0d6744d779a3a05c1d5b28200","value":"Dl Size...: 100%"}},"a964e85b42994d35bffc155d6f6a9632":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47a72460595941f4926eb83df80bba38","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28dffb4ede574666b92d154b75ec1ae2","value":1}},"44c6a36a88864eeba970cc78b0072e8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a295633cbb3d48eb8083e326abf1f6b8","placeholder":"​","style":"IPY_MODEL_41d564a1bcc74e539c0e53f9c24e8ecc","value":" 4764/4764 [04:33&lt;00:00, 25.65 MiB/s]"}},"191675820f204017938ac7c2b2f07a88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16f413f9ba2449eca9c12ea5f87eb21d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea078c0d6744d779a3a05c1d5b28200":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47a72460595941f4926eb83df80bba38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"28dffb4ede574666b92d154b75ec1ae2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a295633cbb3d48eb8083e326abf1f6b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41d564a1bcc74e539c0e53f9c24e8ecc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30c79eb65a744d4ab43c56b509625aa9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e20975e875841a58e6ec7d03ba893e0","IPY_MODEL_c8d7b83d4f0c4ec6a3382d42c1b8fd94","IPY_MODEL_a4840fff03884f32a4dca42eaf730810"],"layout":"IPY_MODEL_3722857f6f2b41d0b952306f4258249f"}},"6e20975e875841a58e6ec7d03ba893e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_094354834b3440649543bd7edf719206","placeholder":"​","style":"IPY_MODEL_45b883b7cfe240999682079043387c15","value":"Extraction completed...: 100%"}},"c8d7b83d4f0c4ec6a3382d42c1b8fd94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdd06adc7cb342f6a755fb431ad9c53d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9f4df1566a54c0db543ad00dfb7bb21","value":1}},"a4840fff03884f32a4dca42eaf730810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_021e38b270f645b5a4ec044d2f7d0380","placeholder":"​","style":"IPY_MODEL_d968ea785b5442f696f50c4b32d9a657","value":" 1/1 [04:33&lt;00:00, 273.30s/ file]"}},"3722857f6f2b41d0b952306f4258249f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094354834b3440649543bd7edf719206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b883b7cfe240999682079043387c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdd06adc7cb342f6a755fb431ad9c53d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d9f4df1566a54c0db543ad00dfb7bb21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"021e38b270f645b5a4ec044d2f7d0380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d968ea785b5442f696f50c4b32d9a657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60c1e259b01d482ba3693c224c90d3b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c495d4478ca2444f9b00820e3f230722","IPY_MODEL_b8e10edc838e4359bfcc16a96f497bb3","IPY_MODEL_6be3b59ab4084bdebfe656d2b2e7b23c"],"layout":"IPY_MODEL_77a2b731f46841f193653e4ee6c7cd8d"}},"c495d4478ca2444f9b00820e3f230722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c47d09a5b4de4341adc690e00eac621c","placeholder":"​","style":"IPY_MODEL_831d48881d2c4359a8c387f865b5b893","value":""}},"b8e10edc838e4359bfcc16a96f497bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_42c2f9a0af34478abd7fbee11862eb55","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_329cfc52d5f0461f8af6232624d33d03","value":1}},"6be3b59ab4084bdebfe656d2b2e7b23c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4310cf75d1c747aabda94f02e732066b","placeholder":"​","style":"IPY_MODEL_4aa58501b7b34031ae6258b19d0d93be","value":" 75694/0 [01:51&lt;00:00, 824.89 examples/s]"}},"77a2b731f46841f193653e4ee6c7cd8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c47d09a5b4de4341adc690e00eac621c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831d48881d2c4359a8c387f865b5b893":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42c2f9a0af34478abd7fbee11862eb55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"329cfc52d5f0461f8af6232624d33d03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4310cf75d1c747aabda94f02e732066b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa58501b7b34031ae6258b19d0d93be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8862927cf96a434cb6184718a993b316":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a7c94c240d54924aec38407079f31f2","IPY_MODEL_ca1f1dc4b1cd43de93da1997895d724a","IPY_MODEL_50bf719fd0fa4429b14cd2231794a0f6"],"layout":"IPY_MODEL_fea6fa3c204945679d8a81c763578003"}},"9a7c94c240d54924aec38407079f31f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_925d98e4f1d948088339e8e1954fd1de","placeholder":"​","style":"IPY_MODEL_164a3de027284998b2727eec09e0009e","value":"100%"}},"ca1f1dc4b1cd43de93da1997895d724a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_42e2542aa1074961a696720f14bbf7a8","max":75750,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cc5e0aafb254f1389bfe86155f57583","value":75749}},"50bf719fd0fa4429b14cd2231794a0f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3278717c73064224949bc1369be6683d","placeholder":"​","style":"IPY_MODEL_0a226f059de84298a2d28798145091a9","value":" 75749/75750 [00:32&lt;00:00, 2417.10 examples/s]"}},"fea6fa3c204945679d8a81c763578003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925d98e4f1d948088339e8e1954fd1de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"164a3de027284998b2727eec09e0009e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42e2542aa1074961a696720f14bbf7a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cc5e0aafb254f1389bfe86155f57583":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3278717c73064224949bc1369be6683d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a226f059de84298a2d28798145091a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"098ef1df43b44307af191a8a210a5627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa50bb2a928b4c83a5de7233ded02bcc","IPY_MODEL_3e6687a9f6d848308dbc455fb61a7a5f","IPY_MODEL_e4ac2b9b83fa47acbb8b3740a7e5c2d0"],"layout":"IPY_MODEL_a176cec8ba6d4e0aa473b3a8ee585b05"}},"aa50bb2a928b4c83a5de7233ded02bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_340a27723b0f4d558abf54e6e5b5fb05","placeholder":"​","style":"IPY_MODEL_8700f9f4d1b8497a9a38b0b6506e2258","value":""}},"3e6687a9f6d848308dbc455fb61a7a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_839b4c0f074946d39d682f21bcd0a775","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b6a53656752448fa8dd8d4c16d4c430","value":1}},"e4ac2b9b83fa47acbb8b3740a7e5c2d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a392973bc4b4773bc0889c927eff156","placeholder":"​","style":"IPY_MODEL_461a044d20f94bd7a0c72c776ebf092d","value":" 25237/0 [00:59&lt;00:00, 463.74 examples/s]"}},"a176cec8ba6d4e0aa473b3a8ee585b05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340a27723b0f4d558abf54e6e5b5fb05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8700f9f4d1b8497a9a38b0b6506e2258":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"839b4c0f074946d39d682f21bcd0a775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7b6a53656752448fa8dd8d4c16d4c430":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a392973bc4b4773bc0889c927eff156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"461a044d20f94bd7a0c72c776ebf092d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14819ecc578440b58f1f80f56a1d604c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_037ab44cf1a74cce9136adcf5a9d9ad9","IPY_MODEL_8116a671ec344fd2bd0fe7fe451827e2","IPY_MODEL_7d602493c170495ca4b00adf8b01b100"],"layout":"IPY_MODEL_3595fd090cac45f398934fd95654e815"}},"037ab44cf1a74cce9136adcf5a9d9ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f36104239d80477da4073fe4af49b437","placeholder":"​","style":"IPY_MODEL_af472e965b254d3392d3ac6a2dbacab3","value":"100%"}},"8116a671ec344fd2bd0fe7fe451827e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d89fd785a83448b09810ecbd65ffb5b6","max":25250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d49c634ddb4f4f32962ffff1e633ccbf","value":25249}},"7d602493c170495ca4b00adf8b01b100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3a68f09feb14e4d97b70e02b66edbd7","placeholder":"​","style":"IPY_MODEL_b8ac949b9d274744bc6a077f7e03a129","value":" 25249/25250 [00:05&lt;00:00, 4725.29 examples/s]"}},"3595fd090cac45f398934fd95654e815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f36104239d80477da4073fe4af49b437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af472e965b254d3392d3ac6a2dbacab3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d89fd785a83448b09810ecbd65ffb5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d49c634ddb4f4f32962ffff1e633ccbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3a68f09feb14e4d97b70e02b66edbd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8ac949b9d274744bc6a077f7e03a129":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}